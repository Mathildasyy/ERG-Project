---
title: "OLS_model"
author: "Sun Yan, He Shuqing"
date: "12/10/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
source('~/Documents/Github/ERG-Project/preprocessing/preprocess.R')
train <- read.csv('~/Documents/Github/ERG-Project/data/train_full2.csv')[,-1] 
# Y <- train[,ncol(train)]
# train <- train[,-ncol(train)]
```


```{r}
library(glmnet)
library(boot)
# train.index = sample(1:nrow(train), 0.7*nrow(train))
# data.train = train[train.index,]
# Y.train = Y[train.index]
#data.train = cbind(data.train, Y.train)
train2 = train[-c(384,313,725,1072,1140),]
glm.fit <- glm(Y~., data = train2)
set.seed(1) 
cv.glm <- cv.glm(train2, glm.fit, K=10)
cv.error <- cv.glm(train2, glm.fit, K=10)$delta[1]
lm.RMSE <- sqrt(cv.error) # 0.1325428
```

```{r}
library(leaps)
regfit.forward = regsubsets(Y~.,data = train, nvmax = 47, method = "forward")
reg.summary <- summary(regfit.forward)

plot(reg.summary$cp, xlab = 'Number of Variables', ylab = 'Cp', type = 'l')
min = which.min(reg.summary$cp)
points(min, reg.summary$cp[min], col =1, cex =2, pch = 20)
min
coef(regfit.forward, min)

forward.RMSE <- sqrt(reg.summary$rss[min]/nrow(train)) # 0.1191135
```

```{r}
library(caret)
fitControl <- trainControl(method = 'repeatedcv',
                           number = 10,
                           repeats = 10)

set.seed(1)
lmFit <- train(Y~., data = train,
               method = 'BstLm',
               trControl = fitControl)
BoostLm.RMSE <- lmFit$results$RMSE[3] # 0.1366453
```


```{r}
# fitControl <- trainControl(method = 'repeatedcv',
#                            number = 10,
#                            repeats = 10)
# lmFit <- train(Y~., data = train,
#                method = '',
#                trControl = fitControl)
# lmFit
```

```{r}
fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 10)

set.seed(1)
L2Fit <- train(Y ~ ., data = train, 
                 method = "glmnet", 
                 trControl = fitControl)

L2.RMSE <- L2Fit$results$RMSE[5] #0.1277953
```


```{r}
set.seed(1)
cv_model_pcr <- train(
  Y ~ ., 
  data = train, 
  method = "pcr",
  trControl = fitControl,
  tuneLength = 100
  )
#0.1279845
```


```{r}
library(leaps)
library(ranger)
library(e1071)
library(glmnet)
library(boot)

fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 10)

# 1. Forward selection
model.fwd <- function(x){
  x1 <- model.matrix(Y~., data = x)
  regfit.forward = regsubsets(Y~.,data = x, nvmax = 47, method = "forward")
  reg.summary <- summary(regfit.forward)
  min = which.min(reg.summary$cp)
  pred <- x1[,names(coef(regfit.forward, min))]%*%coef(regfit.forward, min)
  return(pred)
}

# 2. Principal Component Regression
set.seed(1)
cv_model_pcr <- train(
  Y ~ ., 
  data = train, 
  method = "pcr",
  trControl = fitControl,
  tuneLength = 100
  )

# 3. Boosting Linear Model
set.seed(1)
BstlmFit <- train(Y~., data = train,
               method = 'BstLm',
               trControl = fitControl)

# 4. Lasso Regression
set.seed(1)
L2Fit <- train(Y ~ ., data = train, 
                 method = "glmnet", 
                 trControl = fitControl)

# 5. Random Forest Regression
set.seed(1)
tuned_randomforest_model <- ranger(
    formula         = Y ~ ., 
    data            = train, 
    num.trees       = 1000,
    mtry            = 20,
    min.node.size   = 3,
    sample.fraction = .8,
    importance      = 'impurity'
  )


# # 6. SVR
# for (i in 1:length(train_svm)){
#   if (class(train_svm[,i]) == "character"){
#     train_svm[,i] = as.factor(train_svm[,i])
#   } 
# }
# set.seed(1)
# tc <- tune.control(cross = 10)
# obj_1 <- tune(svm, Y~., kernal = "linear", data = train_svm, ranges = list(gamma = 2^(-2:2), cost = 2^(2:4)), tunecontrol = tc)

```


```{r}
pred_fwd <- model.fwd(train)  # 0.1191135 0.3
pred_pcr <- predict(cv_model_pcr$finalModel,train) # 0.1279845 0.2
pred_bstlm <- predict(BstlmFit,train) # 0.1366453 0.1
pre_L2Fit <- predict(L2Fit,train) # 0.1277953 0.2
pred_ranger <- predict(tuned_randomforest_model, train) # 0.1376053 0.1
pred_svr <- predict(obj_1$best.model, train) # 0.13454717 0.1
  
pred <- 0.3*pred_fwd + 0.2*pred_pcr + 0.1*pred_bstlm + 0.2*pre_L2Fit + 0.1*pred_ranger + 0.1*pred.svr

sqrt(mean((pred - train$Y)^2))
```

```{r}


```



